---
layout: post
title: Compressing viola's higher dimensions
---

In a [previoius entry](http://jfraj.github.io/2015/03/29/goodbadviolastrokes.html), I have shown how to distinguish between a good and bad viola player from their audio recordings.
Every now and then, I re-do the analysis
and I show below that a global distinction between a good and bad player is not straightforward. 

Many thing changes between recordings from instrument tune ups (e.g. new strings) to environment variables (e.g. temperature).  But the setup is basically the same: long strokes of an open (D) string recorded with my laptop's microphone.

I decided to sample regular windows along the signal and exclude those with signal too low.
Below is an example of such a recording.


    import sys
    sys.path.append('../')
    import stroke_cleaning
    
    %matplotlib inline
    import matplotlib.pyplot as plt
    import numpy as np


    figtest = plt.figure(figsize=(10, 3))
    audio = stroke_cleaning.audio_sample('test.wav')
    audio.set_fake_regular_offsets(1)
    audio.isolate_strokes()
    audio.plot_signal(x_axis_type='sample', with_strokes=True)


![png]({{jfraj.github.io}}/assets/viola_pca_files/viola_pca_2_0.png)


The red lines above are the beginning of each windows to determine features from.
##Back on good and bad separation
As before, I record a good (Marina) and a bad (me) player to compare the extracted two features.
Here are two examples taken on different days shown using a script from my github repo "soundeval".


    import check_signal
    fig_features = plt.figure(figsize=[10,5])
    plt.subplot(1,2,1)
    check_signal.plot_features_from_list(('test.wav', 'test_bad.wav'), ('good', 'bad'),
                                         (None, (0,1420000)), fake_stroke_onset=True)
    plt.grid()
    plt.subplot(1,2,2)
    check_signal.plot_features_from_list(('test1.wav', 'test_bad1.wav'), ('good', 'bad'),
                                         (None, (0,1420000)), fake_stroke_onset=True)
    plt.grid()


![png]({{jfraj.github.io}}/assets/viola_pca_files/viola_pca_4_0.png)


In the left plot, the separation is clear, unlike the right one.
Did I suddenly became a good player, catching up with Marina's 20 year's of experience?
That's unlikely since I make a daily effort not to practice to maintain a constant level of mediocrity.
The fruit of my lethargic endeavor is revealed by Marina's annoyance 
for constantly reminding me how to hold the viola.
She even tries to share tips but in the name of science, I only pretend to listen.

Here is all the data so far:


    check_signal.show_players_features(play_type='longbow', verbose=False, wait4show=False, figsize=[12,8],
                                       rangex=(0.03,0.14), rangey=(1000,4000))
    plt.grid()


![png]({{jfraj.github.io}}/assets/viola_pca_files/viola_pca_6_1.png)


It is hard to distinguish, using only these two features, a good from a bad player. 
More information about the audio signal is needed to distinguish the players.

##More features
Up to now, I was considering only two features: zero-crossing rate (zcr) and spectral centroid (centroid).
In addition to these, a quick look at [essentia's algorithm list](http://essentia.upf.edu/documentation/algorithms_reference.html) I added the 
* [Central moments](http://essentia.upf.edu/documentation/reference/std_CentralMoments.html)
* [Distribution shape](http://essentia.upf.edu/documentation/reference/std_DistributionShape.html)
* [Spectral flatness](http://essentia.upf.edu/documentation/reference/std_Flatness.html)
* [Signal variance](http://essentia.upf.edu/documentation/reference/std_Variance.html)

I have put all the features in one csv file:


    import pandas as pd
    df = pd.read_csv('../features_csv/testfeatures_longbow1.csv')
    df.shape




    (1150, 15)



Out of these features, ten have non-unique values.
Let's see if it is possible to find a combination of these features that give a better visual separation.

## Reduced dimensions with PCA
I will use scikit-learn PCA to find the two principal axis of this multi-dimensional data sample.
Let's first put the data in a sklearn-friendly numpy array and convert the player names to integer (marina (good) = 1 other players are bad =0).


    params = ['zrc', 'centroid', 'cm0', 'cm1', 'cm2', 'cm3', 'cm4', 'sm0', 'sm2', 'flatness', 'scomplex', 'var']
    X = df[params].values
    df['y'] = df.player.apply(lambda x: 1 if x == 'marina' else 0)

Before using PCA, values of all dimensions are reduced to a variance of 1 and a mean of 0 with sklearn's `StandardScaler`.
These two can be combined in a pipeline as follow


    from sklearn.decomposition import PCA
    from sklearn.preprocessing import StandardScaler
    from sklearn.pipeline import Pipeline
    pipeline = Pipeline([('scaling', StandardScaler()), ('pca', PCA(n_components=2))])
    Xproj = pipeline.fit_transform(X)
    print(X.shape)
    print(Xproj.shape)

    (1150, 12)
    (1150, 2)


The transformed feature array `Xproj` is now reduced to 2 components as requested by `n_components`.
Let's look at them with different colors for good and bad players.


    figProj, axProj = plt.subplots(figsize=(12,8))
    plt.scatter(Xproj[:, 0], Xproj[:, 1], c=df['y'].values, edgecolor='none', alpha=0.5, s=60)
    axProj.set_xlim([-0.05, 0.2])
    _ = axProj.set_ylim([-4, 4])


![png]({{jfraj.github.io}}/assets/viola_pca_files/viola_pca_16_0.png)


Well, there is still a significant overlap of the good and bad players.
But since I do not want to feel like having done this work for nothing, 
my biased eye see an improvement in the separation.
Nevertheless, supervised training a classifier will hopefuly lead to better results than my eye can do with the above plot.
